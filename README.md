# ğŸš€ Opstream

An AI-powered platform that helps developers discover and contribute to open source projects. The platform uses RAG (Retrieval Augmented Generation) to analyze GitHub repositories and provide intelligent insights, contribution suggestions, and mentorship.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-green.svg)
![React](https://img.shields.io/badge/react-19.x-61DAFB.svg)

## âœ¨ Features

### ğŸ” **Issue Discovery**
- Search for beginner-friendly issues across GitHub
- Filter by domain (React, Python, ML, Rust, Go, etc.)
- Sort by recent activity or popularity

### ğŸ§  **Repository Analysis**
- **RAG-powered Q&A**: Ask questions about any indexed repository
- **Tech Stack Detection**: Automatically identify languages, frameworks, and tools
- **Contribution Suggestions**: Get AI-curated lists of beginner-friendly tasks, bugs, and features
- **Warmth Score**: Evaluate maintainer friendliness (0-100)

### ğŸ’¬ **AI Mentorship**
- Interactive chat with context about the repository
- Code review simulation
- Setup instructions extraction
- Skill requirements analysis for issues

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Qdrant** - Vector database for embeddings
- **Sentence Transformers** - MiniLM-L6-v2 for embeddings (384 dims)
- **Groq (Llama 3.3 70B)** - LLM for analysis and chat
- **PyGithub** - GitHub API integration

### Frontend
- **React 19** + **Vite** - Modern build tooling
- **Three.js** + **React Three Fiber** - 3D visualizations
- **Vanilla CSS** - Premium dark theme design

## ğŸ“‹ Prerequisites

- **Python 3.11+**
- **Node.js 18+**
- **Qdrant** (cloud or local)
- API Keys:
  - GitHub Personal Access Token
  - Groq API Key
  - HuggingFace API Token (optional)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/open-source-intelligence.git
cd open-source-intelligence
```

### 2. Backend Setup

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate
# Activate (macOS/Linux)
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Environment Variables

Create a `.env` file in the root directory:

```env
# Required
GITHUB_TOKEN=ghp_your_github_token_here
GROQ_API_KEY=gsk_your_groq_api_key_here

# Optional
HUGGINGFACEHUB_API_TOKEN=hf_your_token_here
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
# Or for Qdrant Cloud:
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your_qdrant_api_key
```

### 4. Start Qdrant (Local)

Using Docker:
```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

Or use [Qdrant Cloud](https://cloud.qdrant.io/) for free managed hosting.

### 5. Run the Backend

```bash
python -m uvicorn backend.main:app --reload --port 8000
```

### 6. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

The app will be available at `http://localhost:5173`

## ğŸ“ Project Structure

```
open-source-intelligence/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py           # FastAPI app & endpoints
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ engine.py     # RAG engine (Qdrant integration)
â”‚   â”‚   â”œâ”€â”€ fetcher.py    # GitHub data fetcher
â”‚   â”‚   â””â”€â”€ analyzer.py   # LLM-powered analysis
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ github_engine.py  # Issue search engine
â”‚   â””â”€â”€ memory/           # Conversation memory
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx       # Main app component
â”‚   â”‚   â”œâ”€â”€ components/   # React components
â”‚   â”‚   â””â”€â”€ index.css     # Styling
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ .env.example
```

## ğŸŒ API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/domains` | GET | List available domains |
| `/api/issues` | POST | Search beginner-friendly issues |
| `/api/index-repo` | POST | Index a repository |
| `/api/analyze` | POST | Ask questions about a repo |
| `/api/suggest` | POST | Get contribution suggestions |
| `/api/tech-stack` | POST | Detect technology stack |
| `/api/warmth-score` | POST | Calculate maintainer warmth |
| `/api/setup` | POST | Extract setup instructions |
| `/api/difficulty` | POST | Calculate issue difficulty |

---

## ğŸ³ Docker Deployment

### Build and Run Locally

```bash
# Build the image
docker build -t open-source-intelligence .

# Run with environment variables
docker run -p 8000:8000 \
  -e GITHUB_TOKEN=ghp_xxx \
  -e GROQ_API_KEY=gsk_xxx \
  -e QDRANT_URL=https://xxx.qdrant.io \
  -e QDRANT_API_KEY=xxx \
  open-source-intelligence
```

### Docker Compose (Optional)

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - QDRANT_URL=${QDRANT_URL}
      - QDRANT_API_KEY=${QDRANT_API_KEY}
    
  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage

volumes:
  qdrant_storage:
```

---

## ğŸ“ Post-Deployment Checklist

- [ ] Backend health check returns `{"status": "ok"}`
- [ ] Frontend loads and displays the domain filters
- [ ] Issue search works (tests GitHub API)
- [ ] Repository indexing works (tests Qdrant + GitHub)
- [ ] Chat/Analysis works (tests Groq LLM)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Groq](https://groq.com/) for blazing fast LLM inference
- [Qdrant](https://qdrant.tech/) for vector database
- [Sentence Transformers](https://www.sbert.net/) for embeddings
- The open source community ğŸ’œ
